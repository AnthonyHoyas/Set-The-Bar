# BOOKFACE PART ONE
- Repository: `Scrapping Fiesta`
- Type of Challenge: `learning challenge`
- Duration: `2 Day`

## Mission objectives

It is time for a little friendly competition! 
Let's ally the fun with the useful!

The objective of these two days is to manage and scrape the most relevant data from different sources to populate the content of our future application.

Everything goes, API, Web Scrapping, Web Crawling the sky is the limit.

On monday, your scrapping codes will be reviewed by Micha and I.

And following evaluations pointers, we'll attribute scores to your scrapping.

### Evaluation Pointers

* Did I manage to get enough data to populate my website and make it relevant?

* Is all my data comming from one or several sources?

* Is the quality of my data consistent troughout my different sources?

* Do I have Doubles entries in my data?

* Is my code reusable?

* Is my code autonomus?

* Do I handle errors In my code?



## Tech

For this challenge, I reccomend you use the tools presented during the lectures


## TOOLS

* [Puppeteer](https://www.npmjs.com/package/puppeteer)

* [JSDOM](https://www.npmjs.com/package/jsdom)

* [Axios](https://www.npmjs.com/package/axios)



## Some nice (Written) Sources to guide you.

* [Puppeteer Scrapping](https://dev.to/kirillinoz/web-scraping-with-puppeteer-kj7)

* [General Scrapping](https://www.scrapingbee.com/blog/web-scraping-javascript/)

## Deliverables.

On monday, I will ask for your github repo link! 



![](https://media.giphy.com/media/L3bj6t3opdeNddYCyl/giphy.gif)














# scrap
